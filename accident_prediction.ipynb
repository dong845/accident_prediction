{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Haversine class for calculating shortest distance between accident position and \"nodes\" which extracted using \"osmnx\" library.\n",
    "import math\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1 = math.radians(lon1)\n",
    "    lat1 = math.radians(lat1)\n",
    "    lon2 = np.radians(lon2)\n",
    "    lat2 = np.radians(lat2)\n",
    "    # lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6378 # Radius of earth in kilometers\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = ox.graph_from_place('Los Angeles, California', network_type='drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68956, 47)\n",
      "(16509, 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/lyudonghang/opt/anaconda3/envs/interface/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_path = \"US_Accidents_Dec21_updated.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "kaggle_LA = data[data[\"City\"]==\"Los Angeles\"]\n",
    "print(kaggle_LA.shape)\n",
    "kaggle_LA['Start_Time'] =  pd.to_datetime(kaggle_LA['Start_Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "kaggle_LA['Year'] = pd.DatetimeIndex(kaggle_LA['Start_Time']).year\n",
    "kaggle_LA_2020 = kaggle_LA[kaggle_LA[\"Year\"]==2020]\n",
    "print(kaggle_LA_2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49527, 49)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "def addNegativeSamples(df):\n",
    "    global balanced_kaggle_california_df\n",
    "    #Specifying raw dataframe\n",
    "    raw_df = df.copy()\n",
    "    raw_df[\"Accident\"] = 1\n",
    "\n",
    "    #Specifying upper coordinate dataframe\n",
    "    negative_upper_coordinate_df = df.copy()    \n",
    "    negative_upper_coordinate_df[\"Accident\"] = 0\n",
    "\n",
    "    #Specifying lower coordinate dataframe\n",
    "    negative_lower_coordinate_df = df.copy()\n",
    "    negative_lower_coordinate_df[\"Accident\"] = 0\n",
    "    \n",
    "\n",
    "    #Offset \"LONGITUD\" and \"LATITUDE\" with +/- ~100 meters~250m\n",
    "    # negative_upper_coordinate_df[\"Start_Lng\"] = negative_upper_coordinate_df[\"Start_Lng\"].apply(lambda x: x-random.uniform((x/750), (x/300)))\n",
    "    # negative_upper_coordinate_df[\"Start_Lat\"] = negative_upper_coordinate_df[\"Start_Lat\"].apply(lambda x: x-random.uniform((x/750), (x/300)))\n",
    "    negative_upper_coordinate_df[\"Start_Lng\"] = negative_upper_coordinate_df[\"Start_Lng\"].apply(lambda x: x-(x/750))\n",
    "    negative_upper_coordinate_df[\"Start_Lat\"] = negative_upper_coordinate_df[\"Start_Lat\"].apply(lambda x: x-(x/750))\n",
    "\n",
    "\n",
    "    # negative_lower_coordinate_df[\"Start_Lng\"] = negative_lower_coordinate_df[\"Start_Lng\"].apply(lambda x: x+random.uniform((x/750), (x/300)))\n",
    "    # negative_lower_coordinate_df[\"Start_Lat\"] = negative_lower_coordinate_df[\"Start_Lat\"].apply(lambda x: x+random.uniform((x/750), (x/300)))   \n",
    "    negative_lower_coordinate_df[\"Start_Lng\"] = negative_lower_coordinate_df[\"Start_Lng\"].apply(lambda x: x+(x/750))\n",
    "    negative_lower_coordinate_df[\"Start_Lat\"] = negative_lower_coordinate_df[\"Start_Lat\"].apply(lambda x: x+(x/750))   \n",
    "\n",
    "    balanced_kaggle_california_df = pd.concat([raw_df, negative_lower_coordinate_df, negative_upper_coordinate_df],ignore_index=True)\n",
    "    return balanced_kaggle_california_df\n",
    "\n",
    "kaggle_LA_2020 = addNegativeSamples(kaggle_LA_2020)\n",
    "print(kaggle_LA_2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  Severity          Start_Time             End_Time  Start_Lat  \\\n",
      "0  A-1735388         2 2020-11-28 01:33:00  2020-11-28 03:13:16  33.963490   \n",
      "1  A-1735405         2 2020-11-10 02:32:00  2020-11-10 04:46:20  34.152964   \n",
      "2  A-1735564         2 2020-11-20 08:47:00  2020-11-20 12:17:14  34.051600   \n",
      "3  A-1735606         2 2020-12-22 12:38:30  2020-12-22 20:46:30  33.981910   \n",
      "4  A-1735607         2 2020-12-10 20:34:30  2020-12-10 21:33:30  34.135160   \n",
      "\n",
      "    Start_Lng    End_Lat     End_Lng  Distance(mi)  \\\n",
      "0 -118.370694  33.963061 -118.370409         0.034   \n",
      "1 -118.278776  34.153274 -118.277476         0.077   \n",
      "2 -118.458568  34.052739 -118.458171         0.082   \n",
      "3 -118.288154  33.982370 -118.281096         0.406   \n",
      "4 -118.358750  34.139809 -118.365350         0.496   \n",
      "\n",
      "                                         Description  ...   Stop  \\\n",
      "0  Incident on S LA CIENEGA BLVD near W FLORENCE ...  ...   True   \n",
      "1                            EB 134 JWO I5. 3 VEH TC  ...  False   \n",
      "2  LAPD 1023 AT VA 11500 WILSHIRE BLVD. POSS 2000...  ...  False   \n",
      "3  Slow traffic from S Vermont Ave (W Gage Ave) t...  ...  False   \n",
      "4  Slow traffic on Hollywood Fwy N - US-101 N fro...  ...  False   \n",
      "\n",
      "  Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n",
      "0           False           True        False          Night          Night   \n",
      "1           False          False        False          Night          Night   \n",
      "2           False          False        False            Day            Day   \n",
      "3           False          False        False            Day            Day   \n",
      "4           False          False        False          Night          Night   \n",
      "\n",
      "  Nautical_Twilight Astronomical_Twilight  Year Accident  \n",
      "0             Night                 Night  2020        1  \n",
      "1             Night                 Night  2020        1  \n",
      "2               Day                   Day  2020        1  \n",
      "3               Day                   Day  2020        1  \n",
      "4             Night                 Night  2020        1  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "(49527, 7)\n"
     ]
    }
   ],
   "source": [
    "print(kaggle_LA_2020.head())\n",
    "kaggle_LA_2020[\"Lat\"] = (kaggle_LA_2020[\"Start_Lat\"]+kaggle_LA_2020[\"End_Lat\"])/2\n",
    "kaggle_LA_2020[\"Lng\"] = (kaggle_LA_2020[\"Start_Lng\"]+kaggle_LA_2020[\"End_Lng\"])/2\n",
    "kaggle_LA_2020_new = kaggle_LA_2020[[\"Lat\", \"Lng\", \"Crossing\", \"Junction\", \"Railway\", \"Station\", \"Accident\"]]\n",
    "print(kaggle_LA_2020_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': 34.1235604, 'x': -118.226157, 'highway': 'stop', 'street_count': 5}\n"
     ]
    }
   ],
   "source": [
    "nodes_list = sorted(list(G.nodes))\n",
    "tmp = nodes_list[100]\n",
    "print(G.nodes[tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'osmid': [907145138, 895315641, 895315642, 398770659], 'lanes': '6', 'name': 'National Boulevard', 'highway': 'secondary', 'maxspeed': '35 mph', 'oneway': False, 'length': 88.746, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821210>}\n",
      "{'osmid': [398770658, 759468526, 759468527], 'oneway': False, 'lanes': '4', 'name': 'National Boulevard', 'highway': 'secondary', 'maxspeed': '35 mph', 'length': 102.25999999999999, 'tunnel': 'yes', 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821290>}\n",
      "{'osmid': 398771138, 'lanes': '5', 'name': 'National Boulevard', 'highway': 'secondary', 'maxspeed': '35 mph', 'oneway': False, 'length': 19.948999999999998, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc7958211d0>}\n",
      "{'osmid': [404964730, 398771139], 'lanes': ['5', '4'], 'name': 'National Boulevard', 'highway': 'secondary', 'maxspeed': '35 mph', 'oneway': False, 'length': 109.153, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821310>}\n",
      "{'osmid': 643327598, 'name': 'Military Avenue', 'highway': 'tertiary', 'oneway': False, 'length': 19.405, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821350>}\n",
      "{'osmid': 1125472054, 'name': 'Military Avenue', 'highway': 'residential', 'oneway': False, 'length': 99.487, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc7958213d0>}\n",
      "{'osmid': 37689821, 'lanes': '4', 'name': 'National Boulevard', 'highway': 'secondary', 'maxspeed': '35 mph', 'oneway': False, 'length': 86.97, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821190>}\n",
      "{'osmid': [13401377, 150945316], 'name': ['Midvale Avenue', 'Sproul Avenue'], 'highway': 'residential', 'oneway': False, 'length': 260.58799999999997, 'geometry': <shapely.geometry.linestring.LineString object at 0x7fc795821450>}\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "for edge in G.edges:\n",
    "    print(G[edge[0]][edge[1]][0])\n",
    "    if temp>6:\n",
    "        break\n",
    "    temp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_num = len(nodes_list)\n",
    "print(\"nodes_num\", nodes_num)\n",
    "feature_matrix = np.zeros((nodes_num,7))\n",
    "labels = []\n",
    "times = 0\n",
    "num_1s = 0\n",
    "num_0s = 0\n",
    "for node in nodes_list:\n",
    "    lats = G.nodes[node][\"y\"]\n",
    "    lngs = G.nodes[node][\"x\"]\n",
    "    if \"street_count\" in G.nodes[node]:\n",
    "        street_count = G.nodes[node][\"street_count\"]\n",
    "    else:\n",
    "        street_count = 0\n",
    "    dist_min = float(\"inf\")\n",
    "    lat_accident = np.array(kaggle_LA_2020_new[\"Lat\"])\n",
    "    lng_accident = np.array(kaggle_LA_2020_new[\"Lng\"])\n",
    "    dist = haversine(lngs, lats, lng_accident, lat_accident)\n",
    "    dist_index = np.argmin(dist)\n",
    "    dist_tmp = np.min(dist)\n",
    "    if dist_tmp<dist_min:\n",
    "        dist_min = dist_tmp\n",
    "        crossing = int(kaggle_LA_2020_new[\"Crossing\"].iloc[dist_index])\n",
    "        junction = int(kaggle_LA_2020_new[\"Junction\"].iloc[dist_index])\n",
    "        railway = int(kaggle_LA_2020_new[\"Railway\"].iloc[dist_index])\n",
    "        station = int(kaggle_LA_2020_new[\"Station\"].iloc[dist_index])\n",
    "    feature_matrix[times, 0] = lats\n",
    "    feature_matrix[times, 1] = lngs\n",
    "    feature_matrix[times, 2] = street_count\n",
    "    feature_matrix[times, 3] = crossing\n",
    "    feature_matrix[times, 4] = junction\n",
    "    feature_matrix[times, 5] = railway\n",
    "    feature_matrix[times, 6] = station\n",
    "    labels.append(kaggle_LA_2020_new[\"Accident\"].iloc[dist_index])\n",
    "    times+=1\n",
    "    if kaggle_LA_2020[\"Accident\"].iloc[dist_index]==1:\n",
    "        num_1s+=1\n",
    "    else:\n",
    "        num_0s+=1\n",
    "print(\"number of 1s:\", num_1s)\n",
    "print(\"number of 0s:\", num_0s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = np.min(feature_matrix[:, 0])\n",
    "lat_max = np.max(feature_matrix[:, 0])\n",
    "lng_min = np.min(feature_matrix[:, 1])\n",
    "lng_max = np.max(feature_matrix[:, 1])\n",
    "# 20 x 20 = 400 blocks\n",
    "lat_interval = (lat_max-lat_min)/20\n",
    "lng_interval = (lng_max-lng_min)/20\n",
    "save_dict = {}\n",
    "for i in range(feature_matrix.shape[0]):\n",
    "    xx = min(int((feature_matrix[i, 0]-lat_min)/lat_interval), 19)\n",
    "    yy = min(int((feature_matrix[i, 1]-lng_min)/lng_interval), 19)\n",
    "    if tuple([xx, yy]) not in save_dict:\n",
    "        save_dict[tuple([xx, yy])] = [i]\n",
    "    else:\n",
    "        save_dict[tuple([xx, yy])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number: 220\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "graphs = []\n",
    "for key in save_dict:\n",
    "    indexes = save_dict[key]\n",
    "    if len(indexes)<=5:\n",
    "        continue\n",
    "    node_features = []\n",
    "    nodes = []\n",
    "    node_labels = []\n",
    "    for index in indexes:\n",
    "        node_features.append(list(feature_matrix[index, :]))\n",
    "        node_labels.append(labels[index])\n",
    "        nodes.append(index)\n",
    "    node_features = np.array(node_features)\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    node_labels = np.array(node_labels)\n",
    "    y = torch.tensor(node_labels)\n",
    "    \n",
    "    sub_G = G.subgraph(nodes)\n",
    "    sources = []\n",
    "    targets = []\n",
    "    edge_attributes = []  # length, bridge, lanes, oneway, maxspeed, tunnel\n",
    "    for edge in sub_G.edges:\n",
    "        sources.append(edge[0])\n",
    "        targets.append(edge[1])\n",
    "        edge_attr = sub_G[edge[0]][edge[1]][0]\n",
    "        if \"length\" in edge_attr:\n",
    "            length = edge_attr[\"length\"]\n",
    "        else:\n",
    "            length = 0\n",
    "        \n",
    "        if \"bridge\" in edge_attr:\n",
    "            if edge_attr[\"bridge\"]==\"yes\":\n",
    "                bridge=1\n",
    "            else:\n",
    "                bridge=0\n",
    "        else:\n",
    "            bridge=0\n",
    "            \n",
    "        if \"tunnel\" in edge_attr:\n",
    "            if edge_attr[\"tunnel\"]==\"yes\":\n",
    "                tunnel=1\n",
    "            else:\n",
    "                tunnel=0\n",
    "        else:\n",
    "            tunnel=0\n",
    "        \n",
    "        if \"lanes\" in edge_attr:\n",
    "            if type(edge_attr[\"lanes\"])==list:\n",
    "                lanes = int(edge_attr[\"lanes\"][0])\n",
    "            else:\n",
    "                lanes = int(edge_attr[\"lanes\"])\n",
    "        else:\n",
    "            lanes = 0\n",
    "        \n",
    "        if \"oneway\" in edge_attr:\n",
    "            oneway = int(edge_attr[\"oneway\"])\n",
    "        else:\n",
    "            oneway = 0\n",
    "            \n",
    "        if \"maxspeed\" in edge_attr:\n",
    "            maxspeed = int(edge_attr[\"maxspeed\"].split()[0])\n",
    "        else:\n",
    "            maxspeed = 0\n",
    "        edge_attributes.append([length, bridge, tunnel, lanes, oneway, maxspeed])\n",
    "    edge_attributes = np.array(edge_attributes)\n",
    "    edge_attr = torch.tensor(edge_attributes, dtype=torch.float)\n",
    "    edge_index = torch.tensor([sources, targets], dtype=torch.long)\n",
    "    data = Data(edge_index=edge_index, x=x, y=y, edge_attr=edge_attr)\n",
    "    graphs.append(data)\n",
    "print(\"total number:\", len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphConv, GCNConv, SAGEConv, GATConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GATConv(7, 64)\n",
    "        self.conv2 = GATConv(64, 64)\n",
    "        self.conv3 = GATConv(64, 64)\n",
    "        self.linear = Linear(64, classes)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, 0.4)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, 0.4)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, 0.4)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "batch_size = 8\n",
    "train_sets = graphs[:-10]\n",
    "test_sets = graphs[-10:]\n",
    "train_loader = DataLoader(train_sets, batch_size=batch_size)\n",
    "model = GNNModel(2)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_loss = float(\"inf\")\n",
    "epochs = 200\n",
    "interval = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    nums = len(train_sets)\n",
    "    for _, data in enumerate(train_loader):\n",
    "        data = data\n",
    "        labels = data.y\n",
    "        predicts = model(data)\n",
    "        loss = criterion(predicts, labels)\n",
    "        losses+=loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch:{epoch}, loss:{losses/nums}\")\n",
    "    avg_loss = losses/nums\n",
    "    if avg_loss<best_loss:\n",
    "        best_loss = avg_loss\n",
    "    if epoch%interval == 0:\n",
    "        model.eval()\n",
    "        acc_avg = 0\n",
    "        times = 0\n",
    "        for _, data in enumerate(test_sets):\n",
    "            _, pred = model(data).max(dim=1)\n",
    "            correct = int(pred.eq(data.y).sum().item())\n",
    "            acc = correct / int(data.x.shape[0])\n",
    "            acc_avg+=acc\n",
    "            times+=1\n",
    "        print(f\"acc: {acc_avg/times}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('interface')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "620def3dd55faa65adc5fe455927ead62dd83ecfc15eeca9e504733b3e5b32d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
